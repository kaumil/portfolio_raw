[{"categories":null,"contents":" In this work, we propose a hybrid binary classifier which combines a decision tree with a support vector machine. The proposed hybrid model has the advantages of improved accuracy and easy interpretability. The model will be useful for feature selection cum classification tasks in real-world supervised learning problems. Numerical evidence is also provided using 25 standard data sets from various fields to assess the performance of the model. Performance of the proposed hybrid binary classifier is quite better when compared to individual classifiers.  ","permalink":"https://kaumil.github.io/portfolio/publications/binaryclassifier/","tags":["Machine Learning","Decision Trees","Support Vector Machines","Classification","Hyrbid models"],"title":"A Hybrid Binary Classifier for Pattern Classification"},{"categories":null,"contents":"","permalink":"https://kaumil.github.io/portfolio/certifications/nptelpython/","tags":["Python","Data Structures","Algorithms"],"title":"Data Structures and Algorithms using Python by IIT Madras"},{"categories":null,"contents":"","permalink":"https://kaumil.github.io/portfolio/certifications/deeplearningspecialization/","tags":["Deep Learning","Neural Networks","Convolutional Neural Networks","Sequence Models"],"title":"Deep Learning Specialization by deeplearning.ai"},{"categories":null,"contents":"","permalink":"https://kaumil.github.io/portfolio/certifications/courseramachinelearning/","tags":["Machine Learning"],"title":"Machine Learning by Stanford University"},{"categories":null,"contents":"","permalink":"https://kaumil.github.io/portfolio/certifications/nptelnlp/","tags":["Natural Language Processing","Word Vectors","Markov Models"],"title":"Natural Language Processing by IIT Kharagpur"},{"categories":null,"contents":"","permalink":"https://kaumil.github.io/portfolio/certifications/pythondeepdive1/","tags":["Python","Advanced Python"],"title":"Python 3: Deep Dive (Part 1-Functional)"},{"categories":null,"contents":"","permalink":"https://kaumil.github.io/portfolio/certifications/udemysparkpython/","tags":["Python","Apache Spark","Spark Mllib","Big Data"],"title":"Spark and Python for Big Data with PySpark"},{"categories":null,"contents":"","permalink":"https://kaumil.github.io/portfolio/certifications/stanfordstatisticallearning/","tags":["Statistical Machine Learning"],"title":"Statistical Learning"},{"categories":null,"contents":"","permalink":"https://kaumil.github.io/portfolio/certifications/udemytamingbigdata/","tags":["Python","Apache Spark","Big Data"],"title":"Taming Big Data with Apache Spark and Python - Hands On!"},{"categories":null,"contents":"Performed EDA on the Advanced Regression: House pricing dataset on Kaggle. Examined various properties like normality, skewness, kurtosis as well as performed log transformations and analyzed the differences using a normal probability plot.\n","permalink":"https://kaumil.github.io/portfolio/projects/creations/advancedregression/","tags":["Regression","scikit-learn","EDA","statistical machine learning"],"title":"Advanced Regression techniques on House pricing datasets"},{"categories":null,"contents":"Emof_ai is a web API which takes a sample video as an input, detects all the faces in each frame of the video and performs classfication. It classifies the emotion of the face into 1 of 8 emotions viz anger, disgust, fear, happy, sad, surprise, neutral and none(this is when there are no faces detected in the frame at all and hence none means no emotion detected in the frame at all). It also classifies the gender of the person. In addition to that, it also classifies the age group of the person into 1 of 4 age groups viz adult, child, old and youth.\nThere are 3 models for each of the 3 tasks. The face detection is done using haarcascade xml and the classification is done using 3 convolutional neural networks, each for one of the 3 tasks and made up of 5 layers. After the processing of the video is done, a data analysis graph is constructed and shown which determines the percent count of each emotion in the video. The percentage of each emotion shows the percentage of detection boxes detected with that emotion. Each emotion is grouped by the gender and the age group. Flask framework is used for the creation of the web API.\n","permalink":"https://kaumil.github.io/portfolio/projects/creations/emofai/","tags":["Convolutional Neural Networks","Keras","Flask","Matplotlib","OpenCV"],"title":"Emof_AI"},{"categories":null,"contents":"Performed Exploratory Analysis on fraud detection dataset and tried to find interaction terms. Moreover, compared various classifiers offered by the scikit-learn library. Classifiers used are:\n Support Vector Classifier (with RBF Kernel) Support Vector Classifier (with Linear Kernel) Random Forests Bagging Classifier Logistic Regression KNN Classifier LDA Classifier GaussianNB Classifier DecisionTree Classifier GradientBoosting Classifier XGBoost Classifier Extra Trees Classifier  ","permalink":"https://kaumil.github.io/portfolio/projects/creations/frauddetection/","tags":["Classification","scikit-learn","Data Analysis","Classifiers comparisions"],"title":"Fraud Detection"},{"categories":null,"contents":"Analysis of the 20 NewsGroup Dataset followed by lemmatization and k-means clustering and non-negative matrix factorization for topic modelling\n","permalink":"https://kaumil.github.io/portfolio/projects/creations/molecularclassification/","tags":["Machine Learning","Clustering","NLP"],"title":"Molecular Classification of Cancer by Gene Expression Monitoring"},{"categories":null,"contents":"Analysis of the 20 NewsGroup Dataset followed by lemmatization and k-means clustering and non-negative matrix factorization for topic modelling\n","permalink":"https://kaumil.github.io/portfolio/projects/creations/topicmodeling/","tags":["Unsupervised learning","K-means clustering","Non-negative matrix factorization"],"title":"Topic Modeling"},{"categories":null,"contents":"Intro Doesn\u0026rsquo;t matter whether it\u0026rsquo;s a CakePHP app for a client, your own personal CMS, or any other web based application. If your passing around passwords or other sensitive info you should really implement SSL. SSL provides 2 main perks to your visitors.\n First it encrypts all communication that flies across the web. This prevents curious or devious billies from getting your secrets. Secondly it ensures to the user that your server is in fact who it claims, and not a nasty \u0026lsquo;man in the middle\u0026rdquo; attack. Finally it gives your site that touch of class\u0026hellip;. which of course a classy person like yourself relies on.  Once you implement SSL certificates on your server you\u0026rsquo;ll want to require secure connections using Apache\u0026rsquo;s rewrite module. Now I won\u0026rsquo;t dwell on the creation and signing of certificates, its already well documented. If your just starting out though,heres a few links I recommend;\n Creating self-signed certificates (free, but should only be used internally or for testing, users will; see an \u0026lsquo;Untrusted\u0026rdquo; warning) Requesting a CA Signed certificate (not free, but the final certificate is trusted and seamless for users)  The second link uses the schools internal CA, you will need to pay a public CA like Entrust or Verisign. All of this information is aimed at \u0026lsquo;nix or solaris servers running apache. Why? cause a production windows server is laughable :-p\nNow that you have a certificate, whats next? So there you are you have a shiny new Certificate and Server key, how do you force visitors to your apache driven site to use the SSL? You copied the certificates into the appropite locations right? And you have made the needed changes in httpd.conf right? So now when you view https://example.com you see a \u0026lsquo;trusted\u0026rsquo; warning or your site right? If No to any of these than this article does a pretty good job of outlining those steps.\nThe SSL Works, How do I force connections to use it? First you need to decide if you want to force every page on your site to use SSL, or only a particular sub-domain, or maybe just your admin directory. Since the overhead is minimal there is no harm is forcing the entire domain to leverage SSL, but if it is a self-signed certificate for your personal use than you\u0026rsquo;ll most certainly want to restrict its use to your own areas. This prevents users from seeing that nasty warning \u0026ldquo;This server is not trusted\u0026rdquo; You\u0026rsquo;ll know if your using SSL because the url prefix changes from http to https (s for secure).\nForcing entire domain to use SSL You want any visit, any where to use ssl. This probably the simplest solution. Create or append to your htaccess file in the top directory of your server. Some people use a port check (80 is typically http, while 443 is https) but if you have alernate configs or the user just adds :8080 to the end of the url this method is useless. Instead check whether the https environmental variable is set, if not then redirect.\nRewriteCond %{HTTPS} !=on RewriteRule ^(.*)$ https://%{SERVER_NAME}$1 \\[R,L\\] Forcing sub-domains to use SSL Maybe you only want mysecretarea.example.com to use SSL, that\u0026rsquo;s easy enough. Its the same premise as above, but you move the htaccess file into the directory that corresponds to the subdomain. Also change the second line like below;\nRewriteCond %{HTTPS} !=on RewriteRule ^(.*)$ https://mysecretarea.%{SERVER_NAME}$1 \\[R,L\\] Forcing a directory to use SSL This method cn get a little hairier if your using aliases or redirects on top of this one. You\u0026rsquo;ll need to consider what order the commands are read. The basic principle is like so. You want all visits to example.com/admin to use ssl. Create a htaccess file in the parent directory. Again will check for the https variable, but this time we also check for the sub-directory to be in the path.\nRewriteCond %{HTTPS} !=on RewriteRule ^/admin/(.*)$ https://%{SERVER_NAME}/admin/$1 \\[R,L\\] ","permalink":"https://kaumil.github.io/portfolio/blog/force-ssl/","tags":["apache","apache","redirect","rewrite","ssl","web development"],"title":"Forcing Visits to use SSL"},{"categories":null,"contents":"Established a mechanism for a user to follow different people and have the posts of the followed people on the home page. Established an \u0026ldquo;Explore\u0026rdquo; feature where a user can explore different posts from all the users on the website in a descending order of the post timestamp. Established a \u0026ldquo;Search\u0026rdquo; feature using Elasticsearch where people can search for a keyword and have relevant posts displayed.\nGithub link: https://github.com/kaumil/flask-blog\n","permalink":"https://kaumil.github.io/portfolio/projects/creations/flask_microblog/","tags":["Flask","SQLAlchemy","Elasticsearch"],"title":"Blogging website"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml\n[outputs] home = [\u0026#34;HTML\u0026#34;, \u0026#34;JSON\u0026#34;] Searching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category\n... \u0026#34;contents\u0026#34;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026#34;tags\u0026#34;:{{ .Params.tags | jsonify }}{{end}}, \u0026#34;categories\u0026#34; : {{ .Params.categories | jsonify }}, ... Edit fuse.js options to Search static/js/search.js\nkeys: [ \u0026#34;title\u0026#34;, \u0026#34;contents\u0026#34;, \u0026#34;tags\u0026#34;, \u0026#34;categories\u0026#34; ] ","permalink":"https://kaumil.github.io/portfolio/search/","tags":null,"title":"Search Results"},{"categories":null,"contents":"Sentiment Analyzer is a ML model as a service made using Flask micro framework. The task is a binary classification problem where I employed CNNs to have a validation accuracy of 84.73% and validation loss of 0.3624. The application serves 2 pipeline: 1 pipeline where the model versions are trained using the jupyter notebook in the sentiment_analysis subfolder. The second pipeline is the inference pipeline where using a config file, Tensorflow Serving is used to deploy that model on a different docker container. The flask and tensorflow container are deployed on the same subnet and orchestrated via docker-compose.\n","permalink":"https://kaumil.github.io/portfolio/projects/creations/cnn_sentiment_analysis/","tags":["Flask","Tensorflow","Convolutional Neural Networks","TfServing","Docker","Classification"],"title":"Sentiment Analyzer"}]